{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1904fbb-ae40-44a9-a093-f0753d1986e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv</td><td>sf-fire-calls.csv</td><td>1137925359</td><td>1576280979000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv",
         "sf-fire-calls.csv",
         1137925359,
         1576280979000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d017c323-ece0-4454-b010-d5a04a692cc7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark is a in-memory data processing framework, why do we need to cache?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a82d64-d22f-4dbd-be5c-8078cca4a2fd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 1. Create a DF (Without Cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b4bf16-501c-495b-9997-834f47922711",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fire_df = (spark\n",
    "           .read\n",
    "           .format(\"csv\")\n",
    "           .option(\"header\", \"true\")\n",
    "           .option(\"inferSchema\", \"true\") # spark will read first block of data to make guess about the columns\n",
    "           .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcdb8372-e365-4e4c-a0a3-b30aeeeab9f6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Try an action on fire_df (loads data from disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f99b0e5-e760-48a3-973d-4fe8ee9b6f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# groupBy, agg, select are transformations and write is an action\n",
    "from pyspark.sql.functions import * \n",
    "(fire_df\n",
    " .groupBy(\"Zipcode of Incident\")\n",
    " .agg(max(\"Delay\").alias(\"MaxDelay\"), min(\"Delay\").alias(\"MinDelay\"))\n",
    " .select(\"Zipcode of Incident\", \"MaxDelay\", \"MinDelay\")\n",
    " .write\n",
    " .format(\"noop\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"/FileStore/temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c3473f4-f218-413b-a24b-f6cca7b5e931",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------+----------------+----------+----------+----------------------+--------------------+--------------------+----+-------------------+---------+------------+----+------------+--------+--------------+--------+---------------+---------+--------+------------------------------+------------------------+-------------------+---------------+--------------------+-------------+------------------+\n|Call Number|Unit ID|Incident Number|        CallType| Call Date|Watch Date|Call Final Disposition|      Available DtTm|             Address|City|Zipcode of Incident|Battalion|Station Area| Box|OrigPriority|Priority|Final Priority|ALS Unit|Call Type Group|NumAlarms|UnitType|Unit sequence in call dispatch|Fire Prevention District|Supervisor District|   Neighborhood|            Location|        RowID|             Delay|\n+-----------+-------+---------------+----------------+----------+----------+----------------------+--------------------+--------------------+----+-------------------+---------+------------+----+------------+--------+--------------+--------+---------------+---------+--------+------------------------------+------------------------+-------------------+---------------+--------------------+-------------+------------------+\n|   20110014|    M29|        2003234|Medical Incident|2002-01-11|2002-01-10|                 Other|01/11/2002 01:58:...|   10TH ST/MARKET ST|  SF|              94103|      B02|          36|2338|           1|       1|             2|    true|           null|        1|   MEDIC|                             1|                       2|                  6|     Tenderloin|(37.7765408927183...|020110014-M29| 5.233333333333333|\n|   20110015|    M08|        2003233|Medical Incident|2002-01-11|2002-01-10|                 Other|01/11/2002 02:10:...| 300 Block of 5TH ST|  SF|              94107|      B03|          08|2243|           1|       1|             2|    true|           null|        1|   MEDIC|                             1|                       3|                  6|South of Market|(37.7792841462441...|020110015-M08|3.0833333333333335|\n|   20110016|    B02|        2003235|  Structure Fire|2002-01-11|2002-01-10|                 Other|01/11/2002 01:47:...|2000 Block of CAL...|  SF|              94109|      B04|          38|3362|           3|       3|             3|   false|           null|        1|   CHIEF|                             6|                       4|                  5|Pacific Heights|(37.7895840679362...|020110016-B02|              3.05|\n|   20110016|    B04|        2003235|  Structure Fire|2002-01-11|2002-01-10|                 Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|              94109|      B04|          38|3362|           3|       3|             3|   false|           null|        1|   CHIEF|                             3|                       4|                  5|Pacific Heights|(37.7895840679362...|020110016-B04| 2.316666666666667|\n|   20110016|     D2|        2003235|  Structure Fire|2002-01-11|2002-01-10|                 Other|01/11/2002 01:47:...|2000 Block of CAL...|  SF|              94109|      B04|          38|3362|           3|       3|             3|   false|           null|        1|   CHIEF|                             4|                       4|                  5|Pacific Heights|(37.7895840679362...| 020110016-D2|3.0166666666666666|\n+-----------+-------+---------------+----------------+----------+----------+----------------------+--------------------+--------------------+----+-------------------+---------+------------+----+------------+--------+--------------+--------+---------------+---------+--------+------------------------------+------------------------+-------------------+---------------+--------------------+-------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "fire_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a4f9776-a6d3-4918-aa4f-68a305db2563",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. Try another action on fire_df (loads data again from the disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd71aee-48b9-4631-971e-d927946995df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(fire_df\n",
    " .select(\"CallType\")\n",
    " .where(\"CallType is not null\")\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .write\n",
    " .format(\"noop\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"/FileStore/temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc1d7d49-d3a4-4627-8a65-587166afa6c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4. DF Creation (With Cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5417976-b3a0-413d-a2e8-57fb80b830d6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: DataFrame[Call Number: int, Unit ID: string, Incident Number: int, CallType: string, Call Date: date, Watch Date: date, Call Final Disposition: string, Available DtTm: string, Address: string, City: string, Zipcode of Incident: int, Battalion: string, Station Area: string, Box: string, OrigPriority: string, Priority: string, Final Priority: int, ALS Unit: boolean, Call Type Group: string, NumAlarms: int, UnitType: string, Unit sequence in call dispatch: int, Fire Prevention District: string, Supervisor District: string, Neighborhood: string, Location: string, RowID: string, Delay: double]"
     ]
    }
   ],
   "source": [
    "fire_df = (spark\n",
    "           .read\n",
    "           .format(\"csv\")\n",
    "           .option(\"header\", \"true\")\n",
    "           .option(\"inferSchema\", \"true\") # spark will read first block of data to make guess about the columns\n",
    "           .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\"))\n",
    "\n",
    "fire_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a30b14d5-cf7f-4367-880e-9c312b916333",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 5. Try an action on fire_df (loads data from disk as this is the 1st action after caching and keeps in memory won't remove from memory as in previous operations where we didnot caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5131c813-44b1-4cbf-a88e-ccdee1ee2b5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# groupBy, agg, select are transformations and write is an action\n",
    "from pyspark.sql.functions import * \n",
    "(fire_df\n",
    " .groupBy(\"Zipcode of Incident\")\n",
    " .agg(max(\"Delay\").alias(\"MaxDelay\"), min(\"Delay\").alias(\"MinDelay\"))\n",
    " .select(\"Zipcode of Incident\", \"MaxDelay\", \"MinDelay\")\n",
    " .write\n",
    " .format(\"noop\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"/FileStore/temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3d0f059-79b5-42d8-a516-9f997f639476",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 6. Try another action on fire_df (uses cached data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd2d9275-e63c-4e57-8bff-23c57bf94eab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(fire_df\n",
    " .select(\"CallType\")\n",
    " .where(\"CallType is not null\")\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(\"count\", ascending=False)\n",
    " .write\n",
    " .format(\"noop\")\n",
    " .mode(\"overwrite\")\n",
    " .save(\"/FileStore/temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a53cbea5-3dff-4a7e-9790-2c71e8961c05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Unpersist DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c3a57f-61e2-490f-902f-d0acf4d5f279",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: DataFrame[Call Number: int, Unit ID: string, Incident Number: int, CallType: string, Call Date: date, Watch Date: date, Call Final Disposition: string, Available DtTm: string, Address: string, City: string, Zipcode of Incident: int, Battalion: string, Station Area: string, Box: string, OrigPriority: string, Priority: string, Final Priority: int, ALS Unit: boolean, Call Type Group: string, NumAlarms: int, UnitType: string, Unit sequence in call dispatch: int, Fire Prevention District: string, Supervisor District: string, Neighborhood: string, Location: string, RowID: string, Delay: double]"
     ]
    }
   ],
   "source": [
    "fire_df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94a81e53-7a3c-4d39-876f-a53b696e53c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1861072618133911,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Caching - Feb 2024",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
