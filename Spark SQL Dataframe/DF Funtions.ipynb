{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f365249d-e667-4fee-950a-def475431ea9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns=[\"Employee_id\",\"Employee Name\", \"Gender\",\"Salary\"]\n",
    "emp_data=(\n",
    "    (1,\"Irfan\", \"M\", 120000),\n",
    "    (2,\"Irfana\", \"F\", 110000),\n",
    "    (3,\"Nikgil\", \"\", 120000),\n",
    "    (4,\"XYZ\", None , 80000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf58fb6e-607c-474a-9bfa-2b2263eb1623",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>80000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000
        ],
        [
         2,
         "Irfana",
         "F",
         110000
        ],
        [
         3,
         "Nikgil",
         "",
         120000
        ],
        [
         4,
         "XYZ",
         null,
         80000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "emp_df=spark.createDataFrame(emp_data, columns)\n",
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d476aee-a5ef-4ffc-8779-671a3a119d27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>Full_Gender</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>Male</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>Female</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td></td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>80000</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "Male"
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "Female"
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         ""
        ],
        [
         4,
         "XYZ",
         null,
         80000,
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Full_Gender",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "emp_df=emp_df.withColumn(\"Full_Gender\", when(emp_df.Gender == \"M\", \"Male\")\n",
    "                                        .when(emp_df.Gender == \"F\", \"Female\")\n",
    "                                        .when(emp_df.Gender.isNull(), \"\")\n",
    "                                        .otherwise(emp_df.Gender))\n",
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc46a398-4e34-4e9e-90d2-9ecc6e863b74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "emp_df1=emp_df.withColumn(\"Sal_Greater_100000\",expr(\"\"\"case when Salary > 100000 Then \"Yes\"\n",
    "                                                         Else \"NO\"\n",
    "                                                         end\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc4cc01a-a0e2-490b-ae9a-9f18138dfe3a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>Full_Gender</th><th>Sal_Greater_100000</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>Male</td><td>Yes</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>Female</td><td>Yes</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td></td><td>Yes</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>80000</td><td></td><td>NO</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "Male",
         "Yes"
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "Female",
         "Yes"
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         "",
         "Yes"
        ],
        [
         4,
         "XYZ",
         null,
         80000,
         "",
         "NO"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Full_Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sal_Greater_100000",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(emp_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c326b9-0e99-457d-98da-5b790595698d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>Full_Gender</th><th>Sal_Greater_100000</th><th>manager_id</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>Male</td><td>Yes</td><td>234</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>Female</td><td>Yes</td><td>234</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td></td><td>Yes</td><td>234</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>80000</td><td></td><td>NO</td><td>234</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "Male",
         "Yes",
         234
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "Female",
         "Yes",
         234
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         "",
         "Yes",
         234
        ],
        [
         4,
         "XYZ",
         null,
         80000,
         "",
         "NO",
         234
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Full_Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sal_Greater_100000",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "manager_id",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "emp_df1=emp_df1.withColumn(\"manager_id\", lit(234))\n",
    "display(emp_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959a5bd4-a54f-4141-97bf-43a70ca0f6a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>Full_Gender</th></tr></thead><tbody><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         "Nikgil",
         "",
         120000,
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Full_Gender",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(emp_df[emp_df.Employee_id == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "520bc807-4663-46e7-bc81-90800baec193",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "emp_df=emp_df.orderBy(desc(\"Salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c876ff32-fc95-42ea-b798-2bcaea2a0c92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'max_sal'>"
     ]
    }
   ],
   "source": [
    "display(emp_df.select(max(\"Salary\").alias(\"max_sal\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88be721b-7515-46ee-b768-9c4130040065",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2841663187176834>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;28mmax\u001B[39m, when\n",
       "\u001B[0;32m----> 2\u001B[0m display(emp_df[emp_df\u001B[38;5;241m.\u001B[39mSalary\u001B[38;5;241m!=\u001B[39m emp_df\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSalary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_sal\u001B[39m\u001B[38;5;124m\"\u001B[39m))\u001B[38;5;241m.\u001B[39mmax_sal])\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2921\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, item)\u001B[0m\n",
       "\u001B[1;32m   2919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n",
       "\u001B[1;32m   2920\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, Column):\n",
       "\u001B[0;32m-> 2921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   2922\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n",
       "\u001B[1;32m   2923\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;241m*\u001B[39mitem)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:43\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     39\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n",
       "\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(_local, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogging\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m _local\u001B[38;5;241m.\u001B[39mlogging:\n",
       "\u001B[1;32m     42\u001B[0m         \u001B[38;5;66;03m# no need to log since this should be internal call.\u001B[39;00m\n",
       "\u001B[0;32m---> 43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     44\u001B[0m     _local\u001B[38;5;241m.\u001B[39mlogging \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3125\u001B[0m, in \u001B[0;36mDataFrame.filter\u001B[0;34m(self, condition)\u001B[0m\n",
       "\u001B[1;32m   3123\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mfilter(condition)\n",
       "\u001B[1;32m   3124\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(condition, Column):\n",
       "\u001B[0;32m-> 3125\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   3126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   3127\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m   3128\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN_OR_STRING\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   3129\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcondition\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(condition)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n",
       "\u001B[1;32m   3130\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: Resolved attribute(s) max_sal#366L missing from Employee_id#2L,Employee Name#3,Gender#4,Salary#5L,Full_Gender#19 in operator !Filter NOT (Salary#5L = max_sal#366L).;\n",
       "!Filter NOT (Salary#5L = max_sal#366L)\n",
       "+- Sort [Salary#5L DESC NULLS LAST], true\n",
       "   +- Sort [Salary#5L ASC NULLS FIRST], true\n",
       "      +- Project [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L, CASE WHEN (Gender#4 = M) THEN Male WHEN (Gender#4 = F) THEN Female WHEN isnull(Gender#4) THEN  ELSE Gender#4 END AS Full_Gender#19]\n",
       "         +- LogicalRDD [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2841663187176834>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;28mmax\u001B[39m, when\n\u001B[0;32m----> 2\u001B[0m display(emp_df[emp_df\u001B[38;5;241m.\u001B[39mSalary\u001B[38;5;241m!=\u001B[39m emp_df\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSalary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_sal\u001B[39m\u001B[38;5;124m\"\u001B[39m))\u001B[38;5;241m.\u001B[39mmax_sal])\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2921\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m   2919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n\u001B[1;32m   2920\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, Column):\n\u001B[0;32m-> 2921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2922\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(item, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m   2923\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;241m*\u001B[39mitem)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:43\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(_local, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogging\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m _local\u001B[38;5;241m.\u001B[39mlogging:\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;66;03m# no need to log since this should be internal call.\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     _local\u001B[38;5;241m.\u001B[39mlogging \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3125\u001B[0m, in \u001B[0;36mDataFrame.filter\u001B[0;34m(self, condition)\u001B[0m\n\u001B[1;32m   3123\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mfilter(condition)\n\u001B[1;32m   3124\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(condition, Column):\n\u001B[0;32m-> 3125\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcondition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3126\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3127\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   3128\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN_OR_STRING\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   3129\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcondition\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(condition)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   3130\u001B[0m     )\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: Resolved attribute(s) max_sal#366L missing from Employee_id#2L,Employee Name#3,Gender#4,Salary#5L,Full_Gender#19 in operator !Filter NOT (Salary#5L = max_sal#366L).;\n!Filter NOT (Salary#5L = max_sal#366L)\n+- Sort [Salary#5L DESC NULLS LAST], true\n   +- Sort [Salary#5L ASC NULLS FIRST], true\n      +- Project [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L, CASE WHEN (Gender#4 = M) THEN Male WHEN (Gender#4 = F) THEN Female WHEN isnull(Gender#4) THEN  ELSE Gender#4 END AS Full_Gender#19]\n         +- LogicalRDD [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: Resolved attribute(s) max_sal#366L missing from Employee_id#2L,Employee Name#3,Gender#4,Salary#5L,Full_Gender#19 in operator !Filter NOT (Salary#5L = max_sal#366L).;\n!Filter NOT (Salary#5L = max_sal#366L)\n+- Sort [Salary#5L DESC NULLS LAST], true\n   +- Sort [Salary#5L ASC NULLS FIRST], true\n      +- Project [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L, CASE WHEN (Gender#4 = M) THEN Male WHEN (Gender#4 = F) THEN Female WHEN isnull(Gender#4) THEN  ELSE Gender#4 END AS Full_Gender#19]\n         +- LogicalRDD [Employee_id#2L, Employee Name#3, Gender#4, Salary#5L], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, when\n",
    "display(emp_df[emp_df.Salary!= emp_df.select(max(\"Salary\").alias(\"max_sal\")).max_sal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062f7d7f-49f7-475b-9a16-bc526dfd91f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns=[\"Employee_id\",\"Employee Name\", \"Gender\",\"Salary\", \"department\"]\n",
    "emp_data=(\n",
    "    (1,\"Irfan\", \"M\", 120000, \"CSE\"),\n",
    "    (2,\"Irfana\", \"F\", 110000,\"CSE\"),\n",
    "    (3,\"Nikgil\", \"\", 120000,\"ECE\"),\n",
    "    (4,\"XYZ\", None , 180000,\"ME\"),\n",
    "    (5,\"ABC\", None , 280000,\"ME\"),\n",
    "    (9,\"ABC2\", None , 280000,\"ME\"),\n",
    "    (6,\"asd\", None , 120000,\"MS\"),\n",
    "    (7,\"XYZasd\", None , 380000,\"MS\"),\n",
    ")\n",
    "emp_df=spark.createDataFrame(emp_data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "399a1d97-27c4-4e1b-8c69-6765ce201ff7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>department</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>CSE</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>CSE</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td>ECE</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>180000</td><td>ME</td></tr><tr><td>5</td><td>ABC</td><td>null</td><td>280000</td><td>ME</td></tr><tr><td>9</td><td>ABC2</td><td>null</td><td>280000</td><td>ME</td></tr><tr><td>6</td><td>asd</td><td>null</td><td>120000</td><td>MS</td></tr><tr><td>7</td><td>XYZasd</td><td>null</td><td>380000</td><td>MS</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "CSE"
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "CSE"
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         "ECE"
        ],
        [
         4,
         "XYZ",
         null,
         180000,
         "ME"
        ],
        [
         5,
         "ABC",
         null,
         280000,
         "ME"
        ],
        [
         9,
         "ABC2",
         null,
         280000,
         "ME"
        ],
        [
         6,
         "asd",
         null,
         120000,
         "MS"
        ],
        [
         7,
         "XYZasd",
         null,
         380000,
         "MS"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b25b3bf-ddbd-44bb-88b0-fa3ef0fe5839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>department</th><th>Rank</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>CSE</td><td>1</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>CSE</td><td>2</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td>ECE</td><td>1</td></tr><tr><td>5</td><td>ABC</td><td>null</td><td>280000</td><td>ME</td><td>1</td></tr><tr><td>9</td><td>ABC2</td><td>null</td><td>280000</td><td>ME</td><td>1</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>180000</td><td>ME</td><td>2</td></tr><tr><td>7</td><td>XYZasd</td><td>null</td><td>380000</td><td>MS</td><td>1</td></tr><tr><td>6</td><td>asd</td><td>null</td><td>120000</td><td>MS</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "CSE",
         1
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "CSE",
         2
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         "ECE",
         1
        ],
        [
         5,
         "ABC",
         null,
         280000,
         "ME",
         1
        ],
        [
         9,
         "ABC2",
         null,
         280000,
         "ME",
         1
        ],
        [
         4,
         "XYZ",
         null,
         180000,
         "ME",
         2
        ],
        [
         7,
         "XYZasd",
         null,
         380000,
         "MS",
         1
        ],
        [
         6,
         "asd",
         null,
         120000,
         "MS",
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Rank",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, rank, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "emp_df=emp_df.withColumn(\"Rank\",dense_rank().over(Window.partitionBy(\"department\").orderBy(desc(\"Salary\"))))\n",
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3231bea7-ac18-4bfb-9d80-c64f73a09b82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>department</th><th>Rank</th></tr></thead><tbody><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>CSE</td><td>2</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>180000</td><td>ME</td><td>2</td></tr><tr><td>6</td><td>asd</td><td>null</td><td>120000</td><td>MS</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         2,
         "Irfana",
         "F",
         110000,
         "CSE",
         2
        ],
        [
         4,
         "XYZ",
         null,
         180000,
         "ME",
         2
        ],
        [
         6,
         "asd",
         null,
         120000,
         "MS",
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Rank",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(emp_df.filter(\"Rank=2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f0b4676-38e8-4e66-b52b-2521f4ae01fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Employee_id</th><th>Employee Name</th><th>Gender</th><th>Salary</th><th>department</th><th>Rank</th><th>row_number</th></tr></thead><tbody><tr><td>1</td><td>Irfan</td><td>M</td><td>120000</td><td>CSE</td><td>1</td><td>1</td></tr><tr><td>2</td><td>Irfana</td><td>F</td><td>110000</td><td>CSE</td><td>2</td><td>2</td></tr><tr><td>3</td><td>Nikgil</td><td></td><td>120000</td><td>ECE</td><td>1</td><td>1</td></tr><tr><td>5</td><td>ABC</td><td>null</td><td>280000</td><td>ME</td><td>1</td><td>1</td></tr><tr><td>9</td><td>ABC2</td><td>null</td><td>280000</td><td>ME</td><td>1</td><td>2</td></tr><tr><td>4</td><td>XYZ</td><td>null</td><td>180000</td><td>ME</td><td>2</td><td>3</td></tr><tr><td>7</td><td>XYZasd</td><td>null</td><td>380000</td><td>MS</td><td>1</td><td>1</td></tr><tr><td>6</td><td>asd</td><td>null</td><td>120000</td><td>MS</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Irfan",
         "M",
         120000,
         "CSE",
         1,
         1
        ],
        [
         2,
         "Irfana",
         "F",
         110000,
         "CSE",
         2,
         2
        ],
        [
         3,
         "Nikgil",
         "",
         120000,
         "ECE",
         1,
         1
        ],
        [
         5,
         "ABC",
         null,
         280000,
         "ME",
         1,
         1
        ],
        [
         9,
         "ABC2",
         null,
         280000,
         "ME",
         1,
         2
        ],
        [
         4,
         "XYZ",
         null,
         180000,
         "ME",
         2,
         3
        ],
        [
         7,
         "XYZasd",
         null,
         380000,
         "MS",
         1,
         1
        ],
        [
         6,
         "asd",
         null,
         120000,
         "MS",
         2,
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Employee_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Employee Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Rank",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "row_number",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc, rank, dense_rank, row_number\n",
    "from pyspark.sql.window import Window\n",
    "emp_df=emp_df.withColumn(\"row_number\",row_number().over(Window.partitionBy(\"department\").orderBy(desc(\"Salary\"))))\n",
    "display(emp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00732c64-3860-43f5-8428-d7db22ccab45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DF Funtions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
